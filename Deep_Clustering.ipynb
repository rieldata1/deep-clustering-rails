{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyM1pWTlxxX77e59AJiLKtAT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rieldata1/deep-clustering-rails/blob/main/Deep_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configurar GPU y activar high-RAM**"
      ],
      "metadata": {
        "id": "72GY_P1p9Wj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar Drive\n",
        "from google import colab\n",
        "colab.drive.mount('/content/drive')\n",
        "\n",
        "# Configurar GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "# Activar high-RAM\n",
        "import psutil\n",
        "ram_gb = psutil.virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "537a0zTL9qbT",
        "outputId": "6c77828e-d538-4f61-f632-8d192971a036"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Tue Sep  2 20:17:00 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   50C    P0             28W /   72W |    1041MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Your runtime has 56.9 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deep_Clustering: carga NPZ + AE + K-sweep + DEC (+ IDEC)**\n",
        "* Este notebook consumir√° los NPZ generados por \"Scalograms\".\n",
        "* Optimizaciones: GPU, AMP (mixed precision), prefetch, pin_memory.\n"
      ],
      "metadata": {
        "id": "L_Fnr6U8_PhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **0. Preeliminares**"
      ],
      "metadata": {
        "id": "zE-BJGvW_y6S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5NHoTV16s0M",
        "outputId": "8bbefe7a-cca3-4421-bde5-e3f2bd92e89c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dispositivo: NVIDIA L4\n",
            "Carpeta de ejecuci√≥n: /content/drive/MyDrive/Deep_Cluster/experiments/run_20250902_201700\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "#  PRELIMINARES: Par√°metros + Imports + Runtime/Device + Utils\n",
        "# ============================================================\n",
        "\n",
        "# -----------------------------\n",
        "# PAR√ÅMETROS (ajusta solo esta secci√≥n)\n",
        "# -----------------------------\n",
        "BASE_DIR           = \"/content/drive/MyDrive/Deep_Cluster\"\n",
        "EXPERIMENTS_DIR    = f\"{BASE_DIR}/experiments\"\n",
        "\n",
        "# Carga de datos\n",
        "PRELOAD_DATA       = True\n",
        "PRELOAD_MAX_GB     = 4.0\n",
        "IMG_NORMALIZE_AGAIN= False\n",
        "\n",
        "# DataLoader\n",
        "BATCH_AE           = 64\n",
        "BATCH_EMB          = 128\n",
        "BATCH_DEC          = 64\n",
        "NUM_WORKERS        = 2\n",
        "PIN_MEMORY         = True\n",
        "PERSISTENT_WORKERS = True\n",
        "\n",
        "# Modelo / Entrenamiento\n",
        "IMG_SIZE           = (256, 256)\n",
        "LATENT_DIM         = 128\n",
        "BACKBONE           = \"base\"      # 'small' | 'base' | 'large'\n",
        "DROPOUT_P          = 0.0\n",
        "\n",
        "AE_EPOCHS          = 25\n",
        "AE_LR              = 1e-3\n",
        "AE_WD              = 1e-5\n",
        "AE_LOSS            = \"l1\"\n",
        "USE_AMP            = True\n",
        "\n",
        "# K auto\n",
        "K_MIN              = 2\n",
        "K_MAX              = 10\n",
        "K_FIXED            = None\n",
        "K_RANDOM_STATE     = 2025\n",
        "\n",
        "# DEC\n",
        "DEC_EPOCHS         = 40\n",
        "DEC_LR             = 1e-4\n",
        "DEC_WD             = 0.0\n",
        "DEC_UPDATE_INT     = 1\n",
        "DEC_TOL            = 1e-3\n",
        "\n",
        "# IDEC (opcional)\n",
        "RUN_IDEC           = False\n",
        "IDEC_EPOCHS        = 40\n",
        "IDEC_LR            = 1e-4\n",
        "IDEC_WD            = 0.0\n",
        "IDEC_LAMBDA_REC    = 1e-2\n",
        "IDEC_UPDATE_INT    = 1\n",
        "IDEC_TOL           = 1e-3\n",
        "\n",
        "# Visualizaci√≥n / Guardado\n",
        "RUN_TSNE_2D        = True\n",
        "TSNE_PERPLEXITY    = 30\n",
        "SEED               = 2025\n",
        "SAVE_ARTIFACTS     = True\n",
        "\n",
        "# -----------------------------\n",
        "# IMPORTS\n",
        "# -----------------------------\n",
        "import os, time, csv, math, gc, json, random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from datetime import datetime\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# üëâ IMPORTANTE: tqdm (no 'auto' para evitar widgets en GitHub)\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -----------------------------\n",
        "# Runtime / Device\n",
        "# -----------------------------\n",
        "def seed_everything(seed=SEED):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    if hasattr(torch, \"set_float32_matmul_precision\"):\n",
        "        torch.set_float32_matmul_precision(\"high\")\n",
        "\n",
        "seed_everything(SEED)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"‚úÖ Dispositivo:\", torch.cuda.get_device_name(0) if DEVICE.type==\"cuda\" else \"CPU\")\n",
        "\n",
        "os.makedirs(EXPERIMENTS_DIR, exist_ok=True)\n",
        "RUN_DIR = os.path.join(EXPERIMENTS_DIR, datetime.now().strftime(\"run_%Y%m%d_%H%M%S\"))\n",
        "os.makedirs(RUN_DIR, exist_ok=True)\n",
        "print(\"Carpeta de ejecuci√≥n:\", RUN_DIR)\n",
        "\n",
        "# -----------------------------\n",
        "# Utils\n",
        "# -----------------------------\n",
        "def sizeof_gb(n_items, h, w, bytes_per=2):\n",
        "    return (n_items * h * w * bytes_per) / (1024**3)\n",
        "\n",
        "def count_params(m):\n",
        "    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1) DATASET**"
      ],
      "metadata": {
        "id": "VmVHfJQDDuAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 1) DATASET (no supervisado): descubre .npz y carga escalogramas\n",
        "# ============================================================\n",
        "import glob\n",
        "import bisect\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
        "npz_files = sorted(glob.glob(os.path.join(DATA_DIR, \"*.npz\")))\n",
        "if not npz_files:\n",
        "    raise FileNotFoundError(f\"No hay .npz en {DATA_DIR}. ¬øYa corriste 'Scalograms'?\")\n",
        "\n",
        "print(f\"[SCAN] .npz encontrados: {len(npz_files)}\")\n",
        "for p in npz_files[:3]: print(\"  ‚Ä¢\", p)\n",
        "if len(npz_files) > 3: print(\"  ‚Ä¢ ‚Ä¶\")\n",
        "\n",
        "class NPZManifest:\n",
        "    def __init__(self, files):\n",
        "        self.files = list(files)\n",
        "        self.counts, self.cumcounts = [], [0]\n",
        "        self.img_h = None; self.img_w = None\n",
        "        for p in self.files:\n",
        "            d = np.load(p, allow_pickle=True)\n",
        "            X = d[\"X\"]  # (B,H,W)\n",
        "            B, H, W = X.shape\n",
        "            self.counts.append(B)\n",
        "            self.cumcounts.append(self.cumcounts[-1] + B)\n",
        "            if self.img_h is None:\n",
        "                self.img_h, self.img_w = int(H), int(W)\n",
        "            else:\n",
        "                if (self.img_h, self.img_w) != (int(H), int(W)):\n",
        "                    raise ValueError(f\"Tama√±os inconsistentes: {p} tiene {(H,W)} vs {(self.img_h,self.img_w)}\")\n",
        "        self.total = self.cumcounts[-1]\n",
        "\n",
        "    def __len__(self): return self.total\n",
        "\n",
        "    def locate(self, global_idx):\n",
        "        # usa bisect para encontrar el bloque\n",
        "        file_idx = bisect.bisect_right(self.cumcounts, global_idx) - 1\n",
        "        local_idx = global_idx - self.cumcounts[file_idx]\n",
        "        return self.files[file_idx], int(local_idx)\n",
        "\n",
        "manifest = NPZManifest(npz_files)\n",
        "print(f\"[MANIFEST] Ventanas={len(manifest)} | HxW={manifest.img_h}x{manifest.img_w}\")\n",
        "\n",
        "# Estima si conviene precargar\n",
        "est_gb = sizeof_gb(len(manifest), manifest.img_h, manifest.img_w, bytes_per=2)  # float16\n",
        "do_preload = PRELOAD_DATA and (est_gb <= PRELOAD_MAX_GB + 1e-9)\n",
        "print(f\"[MEM] ~{est_gb:.2f} GB | Preload={do_preload} (umbral={PRELOAD_MAX_GB} GB)\")\n",
        "\n",
        "class ScalogramUnsupervisedDS(Dataset):\n",
        "    \"\"\"Devuelve (x, '_') con x -> tensor (1,H,W) en [0,1].\"\"\"\n",
        "    def __init__(self, manifest: NPZManifest, preload=False, normalize_again=False):\n",
        "        self.manifest = manifest\n",
        "        self.normalize_again = normalize_again\n",
        "        self.preload = preload\n",
        "        self.cache = {}\n",
        "        if self.preload:\n",
        "            print(\"[LOAD] Precargando .npz a RAM‚Ä¶\")\n",
        "            for p in tqdm(self.manifest.files, desc=\"Precarga\"):\n",
        "                self.cache[p] = np.load(p, allow_pickle=True)[\"X\"]  # (B,H,W) float16\n",
        "\n",
        "    def __len__(self): return len(self.manifest)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        p, j = self.manifest.locate(i)\n",
        "        Xj = self.cache[p][j] if p in self.cache else np.load(p, allow_pickle=True)[\"X\"][j]\n",
        "        x = torch.from_numpy(np.asarray(Xj, dtype=np.float32)).unsqueeze(0)  # (1,H,W)\n",
        "        if IMG_NORMALIZE_AGAIN:\n",
        "            mn, mx = x.min(), x.max()\n",
        "            x = (x - mn) / (mx - mn + 1e-12)\n",
        "            x.clamp_(0.0, 1.0)\n",
        "        return x, \"_\"  # placeholder sin etiquetas reales\n",
        "\n",
        "# Instancia dataset y splits 80/20\n",
        "ds_all = ScalogramUnsupervisedDS(manifest, preload=do_preload, normalize_again=IMG_NORMALIZE_AGAIN)\n",
        "rng = np.random.default_rng(SEED)\n",
        "perm = rng.permutation(len(ds_all))\n",
        "n_tr = int(0.8*len(ds_all))\n",
        "idx_tr, idx_va = perm[:n_tr], perm[n_tr:]\n",
        "\n",
        "from torch.utils.data import Subset\n",
        "ds_train = Subset(ds_all, idx_tr)\n",
        "ds_val   = Subset(ds_all, idx_va)\n",
        "\n",
        "# DataLoaders\n",
        "dl_train = DataLoader(\n",
        "    ds_train, batch_size=BATCH_AE, shuffle=True,\n",
        "    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
        "    persistent_workers=(NUM_WORKERS>0 and PERSISTENT_WORKERS),\n",
        "    drop_last=False\n",
        ")\n",
        "dl_val = DataLoader(\n",
        "    ds_val, batch_size=BATCH_AE, shuffle=False,\n",
        "    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
        "    persistent_workers=(NUM_WORKERS>0 and PERSISTENT_WORKERS),\n",
        "    drop_last=False\n",
        ")\n",
        "def make_all_loader(ds, bs=BATCH_EMB):\n",
        "    return DataLoader(\n",
        "        ds, batch_size=bs, shuffle=False,\n",
        "        num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
        "        persistent_workers=(NUM_WORKERS>0 and PERSISTENT_WORKERS),\n",
        "        drop_last=False\n",
        "    )\n",
        "dl_all = make_all_loader(ds_all, bs=BATCH_EMB)\n",
        "\n",
        "print(f\"[DATA] Train={len(ds_train)} | Val={len(ds_val)} | Total={len(ds_all)} | HxW={manifest.img_h}x{manifest.img_w}\")\n",
        "\n",
        "# Vista r√°pida (opcional)\n",
        "def show_grid_samples(dataset, n=12, rows=3, cols=4, title=\"Muestras (sin etiquetas)\"):\n",
        "    n = min(n, len(dataset), rows*cols)\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(1.8*cols, 1.6*rows), sharex=True, sharey=True)\n",
        "    axes = np.array(axes).reshape(-1)\n",
        "    idxs = rng.choice(len(dataset), size=n, replace=False)\n",
        "    for k, i in enumerate(idxs):\n",
        "        x, _ = dataset[i]\n",
        "        axes[k].imshow(x.squeeze(0).numpy(), origin=\"lower\", aspect=\"auto\", cmap=\"turbo\")\n",
        "        axes[k].set_xticks([]); axes[k].set_yticks([])\n",
        "    for a in axes[n:]: a.axis(\"off\")\n",
        "    fig.suptitle(title); plt.tight_layout(); plt.show()\n",
        "\n",
        "# show_grid_samples(ds_all, n=12, rows=3, cols=4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCzoIR6ZDtSR",
        "outputId": "65f31e6e-59e9-4ab9-8de5-24437dda6bb3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SCAN] .npz encontrados: 29\n",
            "  ‚Ä¢ /content/drive/MyDrive/Deep_Cluster/data/scalos_train_000.npz\n",
            "  ‚Ä¢ /content/drive/MyDrive/Deep_Cluster/data/scalos_train_001.npz\n",
            "  ‚Ä¢ /content/drive/MyDrive/Deep_Cluster/data/scalos_train_002.npz\n",
            "  ‚Ä¢ ‚Ä¶\n",
            "[MANIFEST] Ventanas=1800 | HxW=256x256\n",
            "[MEM] ~0.22 GB | Preload=True (umbral=4.0 GB)\n",
            "[LOAD] Precargando .npz a RAM‚Ä¶\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Precarga: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:01<00:00, 15.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DATA] Train=1440 | Val=360 | Total=1800 | HxW=256x256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SHv6C2wgDtAq"
      }
    }
  ]
}