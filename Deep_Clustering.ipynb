{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNi2daVkbbvPzTLNDcHaYwY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rieldata1/deep-clustering-rails/blob/main/Deep_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configurar GPU y activar high-RAM**"
      ],
      "metadata": {
        "id": "72GY_P1p9Wj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar Drive\n",
        "from google import colab\n",
        "colab.drive.mount('/content/drive')\n",
        "\n",
        "# Configurar GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "# Activar high-RAM\n",
        "import psutil\n",
        "ram_gb = psutil.virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "537a0zTL9qbT",
        "outputId": "084cf243-0784-45eb-be19-a0c2c41811dd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Tue Sep  2 19:47:12 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   50C    P8             12W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Your runtime has 56.9 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deep_Clustering: carga NPZ + AE + K-sweep + DEC (+ IDEC)**\n",
        "* Este notebook consumirá los NPZ generados por \"Scalograms\".\n",
        "* Optimizaciones: GPU, AMP (mixed precision), prefetch, pin_memory.\n"
      ],
      "metadata": {
        "id": "L_Fnr6U8_PhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **0. Preeliminares**"
      ],
      "metadata": {
        "id": "zE-BJGvW_y6S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5NHoTV16s0M",
        "outputId": "65de6075-4962-4ba1-c905-999a8de92b2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ GPU detectada: NVIDIA L4\n",
            "Carpeta de ejecución: /content/drive/MyDrive/Deep_Cluster/experiments/run_20250902_200330\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------\n",
        "# PARÁMETROS (ajustar a voluntad)\n",
        "# -----------------------------\n",
        "# Rutas (apunta al índice creado por \"Scalograms.ipynb\")\n",
        "BASE_DIR           = \"/content/drive/MyDrive/Deep_Cluster\"\n",
        "INDEX_CSV          = f\"{BASE_DIR}/meta/scalos_train_index.csv\"     # índice principal\n",
        "EXPERIMENTS_DIR    = f\"{BASE_DIR}/experiments\"                     # carpeta para guardar resultados (modelos, history)\n",
        "\n",
        "# Carga de datos\n",
        "PRELOAD_DATA       = True      # True: intenta precargar todos los NPZ en RAM si caben; False: lee por streaming\n",
        "PRELOAD_MAX_GB     = 4.0       # umbral aprox para decidir si precarga (ajústalo según tu Colab Pro)\n",
        "IMG_NORMALIZE_AGAIN= False     # renormalizar a [0,1] al vuelo (no debería hacer falta si Scalograms ya normalizó)\n",
        "\n",
        "# Sampler (diagnóstico): balancear por etiqueta simulada (si existe en NPZ)\n",
        "BALANCE_BY_LABEL   = False\n",
        "\n",
        "# Batching / DataLoader\n",
        "BATCH_AE           = 64        # batch para preentrenamiento del Autoencoder\n",
        "BATCH_EMB          = 128       # batch para extraer embeddings\n",
        "BATCH_DEC          = 64        # batch para DEC/IDEC\n",
        "NUM_WORKERS        = 2         # sube si tienes CPU libre; si da problemas, pon 0\n",
        "PIN_MEMORY         = True\n",
        "PERSISTENT_WORKERS = True\n",
        "\n",
        "# Modelo\n",
        "IMG_SIZE           = (256, 256) # se verificará contra el CSV; aquí sirve como referencia\n",
        "LATENT_DIM         = 128        # tamaño del embedding z\n",
        "BACKBONE           = \"base\"     # 'small' | 'base' | 'large' (tamaño de la CNN)\n",
        "DROPOUT_P          = 0.0\n",
        "\n",
        "# Entrenamiento AE (preentrenamiento)\n",
        "AE_EPOCHS          = 25\n",
        "AE_LR              = 1e-3\n",
        "AE_WD              = 1e-5\n",
        "AE_LOSS            = \"l1\"       # 'l1' o 'mse'\n",
        "USE_AMP            = True       # usar mixed precision en GPU (acelera / ahorra RAM)\n",
        "\n",
        "# Barrido de K (auto-K)\n",
        "K_MIN              = 2\n",
        "K_MAX              = 10\n",
        "K_FIXED            = None       # si quieres saltar el barrido, pon un entero (p. ej., 4)\n",
        "K_RANDOM_STATE     = 2025\n",
        "\n",
        "# DEC (clustering profundo)\n",
        "DEC_EPOCHS         = 40\n",
        "DEC_LR             = 1e-4\n",
        "DEC_WD             = 0.0\n",
        "DEC_UPDATE_INT     = 1          # actualizar distribución objetivo P cada N épocas\n",
        "DEC_TOL            = 1e-3       # criterio de estabilidad de asignaciones\n",
        "\n",
        "# IDEC (opcional: DEC + pérdida de reconstrucción)\n",
        "RUN_IDEC           = False\n",
        "IDEC_EPOCHS        = 40\n",
        "IDEC_LR            = 1e-4\n",
        "IDEC_WD            = 0.0\n",
        "IDEC_LAMBDA_REC    = 1e-2\n",
        "IDEC_UPDATE_INT    = 1\n",
        "IDEC_TOL           = 1e-3\n",
        "\n",
        "# Visualización / Evaluación\n",
        "RUN_TSNE_2D        = True\n",
        "TSNE_PERPLEXITY    = 30\n",
        "SEED               = 153\n",
        "\n",
        "# Guardado de artefactos (pesos, centros, history, config)\n",
        "SAVE_ARTIFACTS     = True\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# IMPORTS (solo librerías estándar de Colab)\n",
        "# -----------------------------\n",
        "import os, time, csv, math, gc, json, random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from datetime import datetime\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Runtime / Device (GPU + High-RAM)\n",
        "# -----------------------------\n",
        "def seed_everything(seed=SEED):\n",
        "    \"\"\"Fija semillas y activa pequeñas optimizaciones del backend.\"\"\"\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    # Para CNNs suele acelerar (usa kernel heurístico por tamaño)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    # Precisión alta para matmul en GPUs modernas\n",
        "    if hasattr(torch, \"set_float32_matmul_precision\"):\n",
        "        torch.set_float32_matmul_precision(\"high\")\n",
        "\n",
        "# Asegúrate de seleccionar GPU y High-RAM en: Runtime → Change runtime type\n",
        "seed_everything(SEED)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if DEVICE.type == \"cuda\":\n",
        "    print(\"✅ GPU detectada:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"⚠️  No se detectó GPU: ejecutará en CPU (más lento).\")\n",
        "\n",
        "# Crear carpetas de experimento\n",
        "os.makedirs(EXPERIMENTS_DIR, exist_ok=True)\n",
        "RUN_DIR = os.path.join(EXPERIMENTS_DIR, datetime.now().strftime(\"run_%Y%m%d_%H%M%S\"))\n",
        "os.makedirs(RUN_DIR, exist_ok=True)\n",
        "print(\"Carpeta de ejecución:\", RUN_DIR)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Utils simples\n",
        "# -----------------------------\n",
        "def sizeof_gb(n_items, h, w, bytes_per=2):\n",
        "    \"\"\"Estimación de tamaño (GB) para n_items imágenes HxW en float16 (2 bytes por valor).\"\"\"\n",
        "    return (n_items * h * w * bytes_per) / (1024**3)\n",
        "\n",
        "def count_params(m):\n",
        "    \"\"\"Cuenta parámetros entrenables de un modelo.\"\"\"\n",
        "    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n"
      ]
    }
  ]
}