{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyM1pWTlxxX77e59AJiLKtAT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rieldata1/deep-clustering-rails/blob/main/Deep_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configurar GPU y activar high-RAM**"
      ],
      "metadata": {
        "id": "72GY_P1p9Wj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar Drive\n",
        "from google import colab\n",
        "colab.drive.mount('/content/drive')\n",
        "\n",
        "# Configurar GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "# Activar high-RAM\n",
        "import psutil\n",
        "ram_gb = psutil.virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "537a0zTL9qbT",
        "outputId": "6c77828e-d538-4f61-f632-8d192971a036"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Tue Sep  2 20:17:00 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   50C    P0             28W /   72W |    1041MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Your runtime has 56.9 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deep_Clustering: carga NPZ + AE + K-sweep + DEC (+ IDEC)**\n",
        "* Este notebook consumirá los NPZ generados por \"Scalograms\".\n",
        "* Optimizaciones: GPU, AMP (mixed precision), prefetch, pin_memory.\n"
      ],
      "metadata": {
        "id": "L_Fnr6U8_PhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **0. Preeliminares**"
      ],
      "metadata": {
        "id": "zE-BJGvW_y6S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5NHoTV16s0M",
        "outputId": "8bbefe7a-cca3-4421-bde5-e3f2bd92e89c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dispositivo: NVIDIA L4\n",
            "Carpeta de ejecución: /content/drive/MyDrive/Deep_Cluster/experiments/run_20250902_201700\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "#  PRELIMINARES: Parámetros + Imports + Runtime/Device + Utils\n",
        "# ============================================================\n",
        "\n",
        "# -----------------------------\n",
        "# PARÁMETROS (ajusta solo esta sección)\n",
        "# -----------------------------\n",
        "BASE_DIR           = \"/content/drive/MyDrive/Deep_Cluster\"\n",
        "EXPERIMENTS_DIR    = f\"{BASE_DIR}/experiments\"\n",
        "\n",
        "# Carga de datos\n",
        "PRELOAD_DATA       = True\n",
        "PRELOAD_MAX_GB     = 4.0\n",
        "IMG_NORMALIZE_AGAIN= False\n",
        "\n",
        "# DataLoader\n",
        "BATCH_AE           = 64\n",
        "BATCH_EMB          = 128\n",
        "BATCH_DEC          = 64\n",
        "NUM_WORKERS        = 2\n",
        "PIN_MEMORY         = True\n",
        "PERSISTENT_WORKERS = True\n",
        "\n",
        "# Modelo / Entrenamiento\n",
        "IMG_SIZE           = (256, 256)\n",
        "LATENT_DIM         = 128\n",
        "BACKBONE           = \"base\"      # 'small' | 'base' | 'large'\n",
        "DROPOUT_P          = 0.0\n",
        "\n",
        "AE_EPOCHS          = 25\n",
        "AE_LR              = 1e-3\n",
        "AE_WD              = 1e-5\n",
        "AE_LOSS            = \"l1\"\n",
        "USE_AMP            = True\n",
        "\n",
        "# K auto\n",
        "K_MIN              = 2\n",
        "K_MAX              = 10\n",
        "K_FIXED            = None\n",
        "K_RANDOM_STATE     = 2025\n",
        "\n",
        "# DEC\n",
        "DEC_EPOCHS         = 40\n",
        "DEC_LR             = 1e-4\n",
        "DEC_WD             = 0.0\n",
        "DEC_UPDATE_INT     = 1\n",
        "DEC_TOL            = 1e-3\n",
        "\n",
        "# IDEC (opcional)\n",
        "RUN_IDEC           = False\n",
        "IDEC_EPOCHS        = 40\n",
        "IDEC_LR            = 1e-4\n",
        "IDEC_WD            = 0.0\n",
        "IDEC_LAMBDA_REC    = 1e-2\n",
        "IDEC_UPDATE_INT    = 1\n",
        "IDEC_TOL           = 1e-3\n",
        "\n",
        "# Visualización / Guardado\n",
        "RUN_TSNE_2D        = True\n",
        "TSNE_PERPLEXITY    = 30\n",
        "SEED               = 2025\n",
        "SAVE_ARTIFACTS     = True\n",
        "\n",
        "# -----------------------------\n",
        "# IMPORTS\n",
        "# -----------------------------\n",
        "import os, time, csv, math, gc, json, random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from datetime import datetime\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# 👉 IMPORTANTE: tqdm (no 'auto' para evitar widgets en GitHub)\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -----------------------------\n",
        "# Runtime / Device\n",
        "# -----------------------------\n",
        "def seed_everything(seed=SEED):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    if hasattr(torch, \"set_float32_matmul_precision\"):\n",
        "        torch.set_float32_matmul_precision(\"high\")\n",
        "\n",
        "seed_everything(SEED)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"✅ Dispositivo:\", torch.cuda.get_device_name(0) if DEVICE.type==\"cuda\" else \"CPU\")\n",
        "\n",
        "os.makedirs(EXPERIMENTS_DIR, exist_ok=True)\n",
        "RUN_DIR = os.path.join(EXPERIMENTS_DIR, datetime.now().strftime(\"run_%Y%m%d_%H%M%S\"))\n",
        "os.makedirs(RUN_DIR, exist_ok=True)\n",
        "print(\"Carpeta de ejecución:\", RUN_DIR)\n",
        "\n",
        "# -----------------------------\n",
        "# Utils\n",
        "# -----------------------------\n",
        "def sizeof_gb(n_items, h, w, bytes_per=2):\n",
        "    return (n_items * h * w * bytes_per) / (1024**3)\n",
        "\n",
        "def count_params(m):\n",
        "    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1) DATASET**"
      ],
      "metadata": {
        "id": "VmVHfJQDDuAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 1) DATASET (no supervisado): descubre .npz y carga escalogramas\n",
        "# ============================================================\n",
        "import glob\n",
        "import bisect\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
        "npz_files = sorted(glob.glob(os.path.join(DATA_DIR, \"*.npz\")))\n",
        "if not npz_files:\n",
        "    raise FileNotFoundError(f\"No hay .npz en {DATA_DIR}. ¿Ya corriste 'Scalograms'?\")\n",
        "\n",
        "print(f\"[SCAN] .npz encontrados: {len(npz_files)}\")\n",
        "for p in npz_files[:3]: print(\"  •\", p)\n",
        "if len(npz_files) > 3: print(\"  • …\")\n",
        "\n",
        "class NPZManifest:\n",
        "    def __init__(self, files):\n",
        "        self.files = list(files)\n",
        "        self.counts, self.cumcounts = [], [0]\n",
        "        self.img_h = None; self.img_w = None\n",
        "        for p in self.files:\n",
        "            d = np.load(p, allow_pickle=True)\n",
        "            X = d[\"X\"]  # (B,H,W)\n",
        "            B, H, W = X.shape\n",
        "            self.counts.append(B)\n",
        "            self.cumcounts.append(self.cumcounts[-1] + B)\n",
        "            if self.img_h is None:\n",
        "                self.img_h, self.img_w = int(H), int(W)\n",
        "            else:\n",
        "                if (self.img_h, self.img_w) != (int(H), int(W)):\n",
        "                    raise ValueError(f\"Tamaños inconsistentes: {p} tiene {(H,W)} vs {(self.img_h,self.img_w)}\")\n",
        "        self.total = self.cumcounts[-1]\n",
        "\n",
        "    def __len__(self): return self.total\n",
        "\n",
        "    def locate(self, global_idx):\n",
        "        # usa bisect para encontrar el bloque\n",
        "        file_idx = bisect.bisect_right(self.cumcounts, global_idx) - 1\n",
        "        local_idx = global_idx - self.cumcounts[file_idx]\n",
        "        return self.files[file_idx], int(local_idx)\n",
        "\n",
        "manifest = NPZManifest(npz_files)\n",
        "print(f\"[MANIFEST] Ventanas={len(manifest)} | HxW={manifest.img_h}x{manifest.img_w}\")\n",
        "\n",
        "# Estima si conviene precargar\n",
        "est_gb = sizeof_gb(len(manifest), manifest.img_h, manifest.img_w, bytes_per=2)  # float16\n",
        "do_preload = PRELOAD_DATA and (est_gb <= PRELOAD_MAX_GB + 1e-9)\n",
        "print(f\"[MEM] ~{est_gb:.2f} GB | Preload={do_preload} (umbral={PRELOAD_MAX_GB} GB)\")\n",
        "\n",
        "class ScalogramUnsupervisedDS(Dataset):\n",
        "    \"\"\"Devuelve (x, '_') con x -> tensor (1,H,W) en [0,1].\"\"\"\n",
        "    def __init__(self, manifest: NPZManifest, preload=False, normalize_again=False):\n",
        "        self.manifest = manifest\n",
        "        self.normalize_again = normalize_again\n",
        "        self.preload = preload\n",
        "        self.cache = {}\n",
        "        if self.preload:\n",
        "            print(\"[LOAD] Precargando .npz a RAM…\")\n",
        "            for p in tqdm(self.manifest.files, desc=\"Precarga\"):\n",
        "                self.cache[p] = np.load(p, allow_pickle=True)[\"X\"]  # (B,H,W) float16\n",
        "\n",
        "    def __len__(self): return len(self.manifest)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        p, j = self.manifest.locate(i)\n",
        "        Xj = self.cache[p][j] if p in self.cache else np.load(p, allow_pickle=True)[\"X\"][j]\n",
        "        x = torch.from_numpy(np.asarray(Xj, dtype=np.float32)).unsqueeze(0)  # (1,H,W)\n",
        "        if IMG_NORMALIZE_AGAIN:\n",
        "            mn, mx = x.min(), x.max()\n",
        "            x = (x - mn) / (mx - mn + 1e-12)\n",
        "            x.clamp_(0.0, 1.0)\n",
        "        return x, \"_\"  # placeholder sin etiquetas reales\n",
        "\n",
        "# Instancia dataset y splits 80/20\n",
        "ds_all = ScalogramUnsupervisedDS(manifest, preload=do_preload, normalize_again=IMG_NORMALIZE_AGAIN)\n",
        "rng = np.random.default_rng(SEED)\n",
        "perm = rng.permutation(len(ds_all))\n",
        "n_tr = int(0.8*len(ds_all))\n",
        "idx_tr, idx_va = perm[:n_tr], perm[n_tr:]\n",
        "\n",
        "from torch.utils.data import Subset\n",
        "ds_train = Subset(ds_all, idx_tr)\n",
        "ds_val   = Subset(ds_all, idx_va)\n",
        "\n",
        "# DataLoaders\n",
        "dl_train = DataLoader(\n",
        "    ds_train, batch_size=BATCH_AE, shuffle=True,\n",
        "    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
        "    persistent_workers=(NUM_WORKERS>0 and PERSISTENT_WORKERS),\n",
        "    drop_last=False\n",
        ")\n",
        "dl_val = DataLoader(\n",
        "    ds_val, batch_size=BATCH_AE, shuffle=False,\n",
        "    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
        "    persistent_workers=(NUM_WORKERS>0 and PERSISTENT_WORKERS),\n",
        "    drop_last=False\n",
        ")\n",
        "def make_all_loader(ds, bs=BATCH_EMB):\n",
        "    return DataLoader(\n",
        "        ds, batch_size=bs, shuffle=False,\n",
        "        num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
        "        persistent_workers=(NUM_WORKERS>0 and PERSISTENT_WORKERS),\n",
        "        drop_last=False\n",
        "    )\n",
        "dl_all = make_all_loader(ds_all, bs=BATCH_EMB)\n",
        "\n",
        "print(f\"[DATA] Train={len(ds_train)} | Val={len(ds_val)} | Total={len(ds_all)} | HxW={manifest.img_h}x{manifest.img_w}\")\n",
        "\n",
        "# Vista rápida (opcional)\n",
        "def show_grid_samples(dataset, n=12, rows=3, cols=4, title=\"Muestras (sin etiquetas)\"):\n",
        "    n = min(n, len(dataset), rows*cols)\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(1.8*cols, 1.6*rows), sharex=True, sharey=True)\n",
        "    axes = np.array(axes).reshape(-1)\n",
        "    idxs = rng.choice(len(dataset), size=n, replace=False)\n",
        "    for k, i in enumerate(idxs):\n",
        "        x, _ = dataset[i]\n",
        "        axes[k].imshow(x.squeeze(0).numpy(), origin=\"lower\", aspect=\"auto\", cmap=\"turbo\")\n",
        "        axes[k].set_xticks([]); axes[k].set_yticks([])\n",
        "    for a in axes[n:]: a.axis(\"off\")\n",
        "    fig.suptitle(title); plt.tight_layout(); plt.show()\n",
        "\n",
        "# show_grid_samples(ds_all, n=12, rows=3, cols=4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCzoIR6ZDtSR",
        "outputId": "65f31e6e-59e9-4ab9-8de5-24437dda6bb3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SCAN] .npz encontrados: 29\n",
            "  • /content/drive/MyDrive/Deep_Cluster/data/scalos_train_000.npz\n",
            "  • /content/drive/MyDrive/Deep_Cluster/data/scalos_train_001.npz\n",
            "  • /content/drive/MyDrive/Deep_Cluster/data/scalos_train_002.npz\n",
            "  • …\n",
            "[MANIFEST] Ventanas=1800 | HxW=256x256\n",
            "[MEM] ~0.22 GB | Preload=True (umbral=4.0 GB)\n",
            "[LOAD] Precargando .npz a RAM…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Precarga: 100%|██████████| 29/29 [00:01<00:00, 15.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DATA] Train=1440 | Val=360 | Total=1800 | HxW=256x256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SHv6C2wgDtAq"
      }
    }
  ]
}